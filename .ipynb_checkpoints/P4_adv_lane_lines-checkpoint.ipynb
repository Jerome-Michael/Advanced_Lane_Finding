{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Advanced Lane Finding** \n",
    "***\n",
    "Let's start by recalling the main goals of this project: :\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pickle\n",
    "import glob\n",
    "from collections import deque\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Camera Calibration*\n",
    "***\n",
    "Image distortion occurs when a camera looks at 3D objects in real world  and transforms them into a 2D image - this transformation isn’t perfect. Distortion actually changes what the shape and size of these 3D objects appear to be. The reason for this is that we use lenses in our camera system. They cause the light rays often to bend a little too much or too little at the edges of these lenses.\n",
    "So, the first step in analyzing camera images, is to undo this distortion so that you can get correct and useful information out of them.\n",
    "Distortion correction is very important in the field of surveillance of the environment with optical systems as \n",
    "Distortion (if not corrected)changes or makes:\n",
    "> * apparent size of an object in an image\n",
    "> * apparent shape of an object in an image\n",
    "> * an object's apprearance depending on where it's in the field of view\n",
    "> * object's appear closer/farther away than they actually are\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in an image\n",
    "image = mpimg.imread('camera_cal/calibration2.jpg')\n",
    "#printing out some stats and plotting\n",
    "print('This image is:', type(image), 'with dimesions:', image.shape)\n",
    "plt.imshow(image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare object points\n",
    "nx = 9\n",
    "ny = 6\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# arrays to store object points and image points from all the images\n",
    "objpoints = [] # 3D points in real world space\n",
    "imgpoints = [] # 2D points in image plane\n",
    "\n",
    "# prepare object points\n",
    "objp = np.zeros((nx*ny,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2) # x,y coordinates\n",
    "\n",
    "# procedure for each image\n",
    "for fname in images:\n",
    "    # read in each image\n",
    "    img = cv2.imread(fname)\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "    # If found, add object points and image points (draw corners)\n",
    "    if ret == True:\n",
    "        # object and image points\n",
    "        imgpoints.append(corners)\n",
    "        objpoints.append(objp)\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "        print(fname)\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "# save the object and imagepoints in a file    \n",
    "#dist_pickle = {}\n",
    "#dist_pickle[\"objpoints\"] = objpoints\n",
    "#dist_pickle[\"imgpoints\"] = imgpoints\n",
    "#pickle.dump( dist_pickle, open( \"calibration_camera/obj_imgpoints_pickle.p\", \"wb\" ) )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate Camera and undistort picture\n",
    "# Read in an test-image\n",
    "img = cv2.imread('camera_cal/test_image.jpg')\n",
    "\n",
    "# function that takes an image, object points and image points\n",
    "# performs the camera calibration\n",
    "def cal_camera(img, objpoints, imgpoints):\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[0:2], None, None)\n",
    "    # Save the camera calibration result for later use\n",
    "    dist_pickle = {}\n",
    "    dist_pickle[\"mtx\"] = mtx\n",
    "    dist_pickle[\"dist\"] = dist\n",
    "    dist_pickle[\"rvecs\"] = rvecs\n",
    "    dist_pickle[\"tvecs\"] = tvecs\n",
    "    pickle.dump( dist_pickle, open( \"calibration_camera/camera_cal_pickle.p\", \"wb\" ) )    \n",
    "    return \n",
    "\n",
    "# function that takes an image and the camera matrix, distortion coefficients\n",
    "# and returns the undistorted image\n",
    "def cal_undistort_1(img, mtx, dist):\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)  \n",
    "    return undist\n",
    "\n",
    "# calculate the camera matrix and distortion coefficient once\n",
    "cal_camera(img, objpoints, imgpoints)\n",
    "\n",
    "# load the camera matrix and distortion coefficient\n",
    "dist_pickle = pickle.load( open( \"calibration_camera/camera_cal_pickle.p\", \"rb\" ) )\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]\n",
    "# calculate the undistort image\n",
    "undistorted = cal_undistort_1(img, mtx, dist)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "cv2.imwrite('output_images/test_undist.jpg',undistorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Masking and Thresholding*\n",
    "***\n",
    "One important step in creating a successful algorithm for a self-driving car is the correct detection of the driving lanes. In this project we should read image – frames, identify the lanes, perform a perspective transformation and calculat the curveature of the lane. This is a basic step to predict the correct steering angle.\n",
    "\n",
    "At this point I will deal with the image process needed to identify the lanes. Therefore I  defined several possibilities to mask and threshold the images to accurately determine the lane lines even under worse conditions like shadows and lower brightness. \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the camera matrix and distortion coefficient\n",
    "def camera_matrix():\n",
    "    dist_pickle = pickle.load( open( \"calibration_camera/camera_cal_pickle.p\", \"rb\" ) )\n",
    "    mtx = dist_pickle[\"mtx\"]\n",
    "    dist = dist_pickle[\"dist\"]\n",
    "    return mtx, dist\n",
    "\n",
    "def cal_undistort(img, mtx, dist):\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)  \n",
    "    return undist\n",
    "\n",
    "def region_of_interest(img):\n",
    "    #Applies an image mask.\n",
    "    #Only keeps the region of the image defined by the polygon\n",
    "    #formed from `vertices`. The rest of the image is set to black.\n",
    "    # Defining a four sided polygon to mask\n",
    "    imshape = img.shape\n",
    "#    vertices = np.array([[(0.1*imshape[1],imshape[0]),(0.48*imshape[1], imshape[0]/1.7), \\\n",
    "#            (0.52*imshape[1], imshape[0]/1.7), (0.95*imshape[1],imshape[0])]], dtype=np.int32)\n",
    "    vertices = np.array([[(0.*imshape[1],imshape[0]),(0.45*imshape[1], imshape[0]/1.8), \\\n",
    "            (0.55*imshape[1], imshape[0]/1.8), (0.99*imshape[1],imshape[0])]], dtype=np.int32)\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (1,) * channel_count\n",
    "#        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 1 \n",
    "#        ignore_mask_color = 255    \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)   \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img, cv2.CV_64F, 1, 0,ksize=sobel_kernel))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img, cv2.CV_64F, 0, 1,ksize=sobel_kernel))\n",
    "    # Rescale back to 8 bit integer\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # Create a copy and apply the threshold\n",
    "    grad_binary = np.zeros_like(scaled_sobel)\n",
    "    # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "    grad_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return grad_binary\n",
    "\n",
    "def mag_thresh(image, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    mag_binary = np.zeros_like(gradmag)\n",
    "    mag_binary[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "    # Return the binary image\n",
    "    return mag_binary\n",
    "\n",
    "def dir_threshold(image, sobel_kernel=3, dir_thresh=(0, np.pi/2)):\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "     # Calculate gradient direction\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    dir_binary =  np.zeros_like(absgraddir)\n",
    "    dir_binary[(absgraddir >= dir_thresh[0]) & (absgraddir <= dir_thresh[1])] = 1\n",
    "    # Return the binary image\n",
    "    return dir_binary\n",
    "\n",
    "def combined_thresh(img, SOBEL_KERNEL=3, THRESH=(0, 255), MAG_THRESH=(0,255),  DIR_TRESH=(0, np.pi/2)):\n",
    "    # 1) Convert to grayscale\n",
    "#    gray=cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    comb_img =  img#[:,:,0]\n",
    "    # Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(comb_img, orient='x', sobel_kernel=SOBEL_KERNEL, thresh=THRESH)\n",
    "    grady = abs_sobel_thresh(comb_img, orient='y', sobel_kernel=SOBEL_KERNEL, thresh=THRESH)\n",
    "    mag_binary = mag_thresh(comb_img, sobel_kernel=SOBEL_KERNEL, mag_thresh=MAG_THRESH)\n",
    "    dir_binary = dir_threshold(comb_img, sobel_kernel=SOBEL_KERNEL, dir_thresh=DIR_TRESH)\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    return combined\n",
    "\n",
    "def channel_tresh(img,CHL_TRESH=(0, 255)):\n",
    "    s_binary = np.zeros_like(img)\n",
    "    s_binary[(img > CHL_TRESH[0]) & (img <= CHL_TRESH[1])] = 1\n",
    "    return s_binary\n",
    "\n",
    "def img_persp(img):\n",
    "    # 1) determine manually the source points\n",
    "#    src = np.float32([[249, 690],[540, 490],[749, 490],[1058, 690]])\n",
    "    src = np.float32([[249, 690],[579, 460],[704, 460],[1058, 690]])\n",
    "    # 2) define 4 destination points\n",
    "    x_max = img.shape[1]\n",
    "    y_max = img.shape[0]\n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    offset = 0\n",
    "    dst = np.float32([[249, y_max],[249, offset],[1058, offset],[1058, y_max]])\n",
    "    # 3) use cv2.getPerspectiveTransform() to get M, the transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    # 4) use cv2.getPerspectiveTransform() to get inv_M by swapping dst and src\n",
    "    inv_M = cv2.getPerspectiveTransform(dst, src)\n",
    "    # 5) use cv2.warpPerspective() to warp your image to a top-down view\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR) \n",
    "    return warped, M, inv_M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in an image\n",
    "#img = cv2.imread('test_images/straight_lines2.jpg')\n",
    "img = cv2.imread('test_images/test4.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "c_mtx, c_dist = camera_matrix()\n",
    "# calculate the undistort image\n",
    "undist_img = cal_undistort(img, c_mtx, c_dist)\n",
    "### Combine the thresholds\n",
    "### only R channel\n",
    "R_channel = undist_img[:,:,0]\n",
    "R_comb_bin = combined_thresh(R_channel, SOBEL_KERNEL=3, THRESH=(210, 255), MAG_THRESH=(60, 200), DIR_TRESH=(0.7, 1.2))\n",
    "#R_comb_bin = dir_threshold(channel_tresh(R_channel,CHL_TRESH=(210, 255)), sobel_kernel=3, dir_thresh=(0.7, 1.2))\n",
    "#R_comb_bin = channel_tresh(R_channel,CHL_TRESH=(210, 255)) #best pick\n",
    "# mask image\n",
    "msk_R_bin = region_of_interest(R_comb_bin)#.astype(np.float)\n",
    "\n",
    "### Combine the thresholds\n",
    "### only H channel\n",
    "hls = cv2.cvtColor(undist_img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "h1_channel = hls[:,:,0]\n",
    "#H_comb_bin = combined_thresh(h1_channel, SOBEL_KERNEL=9, THRESH=(20, 80), MAG_THRESH=(60, 255), DIR_TRESH=(0.7, 1.2))#best pick\n",
    "H_comb_bin = dir_threshold(channel_tresh(h1_channel,CHL_TRESH=(20, 80)), sobel_kernel=3, dir_thresh=(0.7, 1.2))\n",
    "#H_comb_bin = channel_tresh(h1_channel,CHL_TRESH=(20, 80))\n",
    "# mask image\n",
    "msk_H_bin = region_of_interest(H_comb_bin)\n",
    "\n",
    "### only grayscale cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "G_channel = cv2.cvtColor(undist_img, cv2.COLOR_RGB2GRAY)\n",
    "G_comb_bin = combined_thresh(G_channel, SOBEL_KERNEL=3, THRESH=(100, 200), MAG_THRESH=(10, 225), DIR_TRESH=(0.7, 1.2))\n",
    "#G_comb_bin = dir_threshold(channel_tresh(G_channel,CHL_TRESH=(100, 200)), sobel_kernel=3, dir_thresh=(0.7, 1.2))\n",
    "#G_comb_bin = channel_tresh(G_channel,CHL_TRESH=(100, 200)) #best pick\n",
    "# mask image\n",
    "msk_G_bin = region_of_interest(G_comb_bin)#.astype(np.float)\n",
    "\n",
    "### only S channel\n",
    "s1_channel = hls[:,:,2]\n",
    "#S_comb_bin = combined_thresh(l1_channel, SOBEL_KERNEL=9, THRESH=(85, 255), MAG_THRESH=(60, 200), DIR_TRESH=(0.6, 1.3))\n",
    "#S_comb_bin = dir_threshold(channel_tresh(s1_channel,CHL_TRESH=(85, 255)), sobel_kernel=3, dir_thresh=(0.6, 1.3))\n",
    "S_comb_bin = channel_tresh(s1_channel,CHL_TRESH=(85, 255)) #best pick\n",
    "# mask image\n",
    "msk_S_bin = region_of_interest(S_comb_bin)\n",
    "\n",
    "#comb_binary = np.dstack(( S_comb_bin, H_comb_bin, R_comb_bin))\n",
    "\n",
    "stack_binary = np.dstack(( msk_S_bin,msk_H_bin ,msk_R_bin))\n",
    "# Combine the three binary thresholds\n",
    "#comb_binary = np.zeros_like(msk_H_bin)\n",
    "#comb_binary[(msk_R_bin == 1) | (msk_H_bin == 1)| (msk_S_bin == 1)] = 1\n",
    "\n",
    "comb_binary = cv2.bitwise_or(msk_R_bin*1.,cv2.bitwise_or(msk_S_bin, msk_H_bin))\n",
    "#comb_binary = cv2.bitwise_or(msk_R_bin*1., msk_H_bin)\n",
    "#comb_binary = msk_S_bin\n",
    "\n",
    "# Otsu's thresholding after Gaussian filtering\n",
    "#comb_binary = (comb_binary*255).astype(np.uint8)\n",
    "#blur = cv2.GaussianBlur(comb_binary,(5,5),0)\n",
    "#ret3,comb_binary = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "# Plot the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "#ax2.imshow(stack_binary[:,:,2], cmap='gray')\n",
    "#ax2.imshow(undist_img, cmap='gray')\n",
    "ax2.imshow(comb_binary, cmap='gray')\n",
    "#ax2.set_title('Undistorted Image', fontsize=50)\n",
    "ax2.set_title('Thresholded Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "plt.show()\n",
    "\n",
    "#cv2.imwrite('output_images/test4_undist_001.jpg',comb_binary*255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# perspective transform\n",
    "***\n",
    "The goal of this step is to transform the undistorted image to a \"birds eye view\" of the road. This perspective transform is very similar to the process of the undistortion transform. In this process we don't map object points to image points, but map points in a given image to diverse image points which represent a new perspective. Here we are interested in the perspective of the \"birds eye view\" so that we can concentrate on the lanes seen from above. Those lines should be relatively parallel to each other. This perspective will be very useful for calculation of the lane curvature. I will use the OpenCV functions getPerspectiveTransform and warpPerspective to perform the transformation. To create a perspective transformation, we'll first select four points that define a rectangle on a plane in the original image. Then we'll select where we want those same four points to appear in the warped image.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_points = []\n",
    "\n",
    "# prepare the difined search points for printing in image\n",
    "src = np.float32([[249, 690],[579, 460],[704, 460],[1058, 690]])\n",
    "l = len(src)\n",
    "lines = [[[src[i][0],\n",
    "           src[i][1],\n",
    "           src[(i+1) % l][0],\n",
    "           src[(i+1) % l][1]]] for i in range(l)]\n",
    "\n",
    "for line in lines:\n",
    "    for x1, y1, x2, y2 in line:\n",
    "        cv2.line(img, (x1, y1), (x2, y2), color=[255, 0, 0], thickness=1)\n",
    "\n",
    "# load camera matrix and undistort, warp image\n",
    "c_mtx, c_dist = camera_matrix()\n",
    "#undist_img_2 = cal_undistort(img, c_mtx, c_dist)\n",
    "undist_img = cal_undistort(img, c_mtx, c_dist)\n",
    "top_down_2, perspective_M , inv_M = img_persp(img)\n",
    "top_down, perspective_M , inv_M = img_persp(comb_binary)\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(top_down_2, cmap='gray')\n",
    "ax2.set_title('Undistorted and Warped Image', fontsize=50)\n",
    "ax3.imshow(img, cmap='gray')\n",
    "ax3.set_title('Original Image', fontsize=50)\n",
    "ax4.imshow(top_down, cmap='gray')\n",
    "ax4.set_title('Thresholded and Warped Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=1.7, bottom=0)\n",
    "\n",
    "### posibility to save the images to files    \n",
    "#image_sv = cv2.cvtColor(undist_img, cv2.COLOR_RGB2BGR)\n",
    "#image_sv = undist_img*255.\n",
    "#cv2.imwrite('output_images/straight_lines1_src_002.jpg',image_sv)\n",
    "#image_sv2 = cv2.cvtColor(top_down, cv2.COLOR_RGB2BGR)\n",
    "#image_sv2 = top_down*255.\n",
    "#cv2.imwrite('output_images/straight_lines1_bird_eye_002.jpg',image_sv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# histogram of sum of pixels in the lower half of image\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histogram = np.sum(top_down[int(top_down.shape[0]/2):,:], axis=0)\n",
    "plt.plot(histogram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# RANSAC (RANdom SAmple Consensus) Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import linear_model, datasets\n",
    "#from skimage.transform import PolynomialTransform\n",
    "\n",
    "from sklearn.linear_model import (RANSACRegressor, HuberRegressor)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def Interpol_RanSac(X, y, x_plot):\n",
    "    X = X.reshape(-1, 1)\n",
    "    y = y.reshape(-1, 1)\n",
    "    estimators = [('RANSAC', RANSACRegressor(max_trials = 100, min_samples = 150, \\\n",
    "                                             loss = \"absolute_loss\", \\\n",
    "                                             residual_threshold=15.0,random_state=0))]#,\n",
    "#              ('HuberRegressor', HuberRegressor())]\n",
    "#    colors = {'RANSAC': 'lightgreen'}#, 'HuberRegressor': 'black'}\n",
    "#    linestyle = {'RANSAC': '--'}#, 'HuberRegressor': '--'}\n",
    "#    lw = 3\n",
    "\n",
    "    for name, estimator in estimators:\n",
    "        model = make_pipeline(PolynomialFeatures(2), estimator)\n",
    "        model.fit(X, y)\n",
    "#        mse = mean_squared_error(model.predict(X_test), y_test)\n",
    "        y_plot = model.predict(x_plot[:, np.newaxis])\n",
    "#        plt.plot(x_plot, y_plot, color=colors[name], linestyle=linestyle[name],\n",
    "#                     linewidth=lw, label='%s: ' % (name))\n",
    "#                     linewidth=lw, label='%s: error = %.3f' % (name, mse))\n",
    "    return y_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Histogram search and Polynomial  / RANSAC Algorithm fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implementation of a sliding window and Polynomial Fit\n",
    "def slide_win_poly(top_down, plot_poly):\n",
    "    top_down2 = (top_down*255).astype(np.uint8)\n",
    "    #cv2.convertScaleAbs(top_down, top_down2)\n",
    "\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    ###histogram = np.sum(binary_warped[binary_warped.shape[0]/2:,:], axis=0)\n",
    "    histogram = np.sum(top_down2[int(top_down2.shape[0]/2):,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((top_down2, top_down2, top_down2))#*255\n",
    "\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(top_down.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = top_down2.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 75\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = top_down2.shape[0] - (window+1)*window_height\n",
    "        win_y_high = top_down2.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 3) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 3) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \\\n",
    "                          (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \\\n",
    "                           (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]      \n",
    "        if len(good_left_inds) < 9500:\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "        if len(good_right_inds) < 9500:    \n",
    "            right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    ploty = np.linspace(0, top_down2.shape[0]-1, top_down2.shape[0])\n",
    "    \n",
    "    # Fit with RANSAC\n",
    "    L_RAN_xplot = Interpol_RanSac(lefty, leftx, ploty)\n",
    "    R_RAN_xplot = Interpol_RanSac(righty, rightx, ploty)\n",
    "    \n",
    "   \n",
    "    if plot_poly:\n",
    "        \n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "        \n",
    "#        plt.imshow(out_img)\n",
    "#        plt.xlim(0, 1280)\n",
    "#        plt.ylim(720, 0)\n",
    "#        plt.plot(left_fitx, ploty, color='yellow')\n",
    "#        plt.plot(right_fitx, ploty, color='yellow')\n",
    "#        plt.title('Polynomial Approximation Image', fontsize=20)        \n",
    "\n",
    "        plt.imshow(out_img)\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(720, 0)\n",
    "        plt.plot(L_RAN_xplot, ploty, color='magenta')\n",
    "        plt.plot(R_RAN_xplot, ploty, color='magenta')\n",
    "        plt.title('RANSAC Approximation Image', fontsize=20) \n",
    "#    return L_RAN_xplot, R_RAN_xplot, ploty, out_img, leftx, lefty, rightx, righty\n",
    "    return left_fit, right_fit, ploty, out_img, leftx, lefty, rightx, righty\n",
    "\n",
    "#left_fit, right_fit, ploty, out_img, leftx, lefty, rightx, righty = slide_win_poly(top_down, True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search with polynomial coefficients from previous search and polynomial fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nxt_win_poly(top_down,left_fit, right_fit, plot_poly):\n",
    "    binary_warped= (top_down*255).astype(np.uint8)\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    \n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin = 100\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin))\\\n",
    "                      & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin))\\\n",
    "                    & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    if plot_poly:\n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        \n",
    "        # Create an image to draw on and an image to show the selection window\n",
    "        out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "        window_img = np.zeros_like(out_img)\n",
    "        # Color in left and right line pixels\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "        # Generate a polygon to illustrate the search window area\n",
    "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "        \n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "        result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "        plt.imshow(result)\n",
    "        plt.plot(left_fitx, ploty, color='yellow')\n",
    "        plt.plot(right_fitx, ploty, color='yellow')\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(720, 0)\n",
    "    return left_fit, right_fit, out_img, leftx, lefty, rightx, righty\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Curvature\n",
    "After identifying the lane lines and transforming the lane line pixels in a function form, we are now able to calculate the curvature of the lane and the position of the car in respect to the lane middle. This was done using the formula given in the project introduction. Here calculated with the conversion factors pixel to meter in x and y direction so that the result is in [m]. \n",
    "To calculate the position of the car we first determine the position of the lanes in the image and assume that the camera position is right in the middle of the car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meas_curvature_m(leftx, lefty, rightx, righty, y_eval):\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "    # Fit new polynomials to x,y in world space \n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curve_m = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) \\\n",
    "                            / np.absolute(2*left_fit_cr[0])\n",
    "    right_curve_m = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) \\\n",
    "                            / np.absolute(2*right_fit_cr[0])\n",
    "    curve_m =int((left_curve_m+right_curve_m)/2+0.5)\n",
    "    \n",
    "    left_pos_lane = left_fit_cr[0]*(y_eval*ym_per_pix)**2 + \\\n",
    "                    left_fit_cr[1]*y_eval*ym_per_pix + left_fit_cr[2]\n",
    "    right_pos_lane = right_fit_cr[0]*(y_eval*ym_per_pix)**2 + \\\n",
    "                    right_fit_cr[1]*y_eval*ym_per_pix + right_fit_cr[2]  \n",
    "    mid_pos_car = 1280/2*xm_per_pix\n",
    "    mid_pos_lane = (left_pos_lane+right_pos_lane)/2\n",
    "    dif_pos_car = int((mid_pos_car-mid_pos_lane)*100+0.5)/100\n",
    "    return curve_m, dif_pos_car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meas_RAN_curvature_m(leftx, lefty, rightx, righty, y_eval):\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    ploty_m = ploty*ym_per_pix\n",
    "    L_RAN_xplot_m = Interpol_RanSac(lefty*ym_per_pix, leftx*xm_per_pix, ploty_m)\n",
    "    R_RAN_xplot_m = Interpol_RanSac(righty*ym_per_pix, rightx*xm_per_pix, ploty_m)\n",
    "\n",
    "    L_x1=L_RAN_xplot_m[719]\n",
    "    R_x1=R_RAN_xplot_m[719]\n",
    "    y1=ploty_m[719]\n",
    "    L_x2=L_RAN_xplot_m[359]\n",
    "    R_x2=R_RAN_xplot_m[359]\n",
    "    y2=ploty_m[359]\n",
    "    L_x3=L_RAN_xplot_m[0]\n",
    "    R_x3=R_RAN_xplot_m[0]\n",
    "    y3=ploty_m[0]\n",
    "    # source : http://www.intmath.com/applications-differentiation/8-radius-curvature.php\n",
    "    m1 = (y2-y1)/(L_x2-L_x1)\n",
    "    m2 = (y3-y2)/(L_x3-L_x2)\n",
    "    \n",
    "    xc = (m1*m2*(y1-y3)+m2*(L_x1+L_x2)-m1*(L_x2+L_x3))/(2*(m2-m1))\n",
    "    yc = -(xc-(L_x1+L_x2)/2)/m1+(y1+y2)/2\n",
    "    \n",
    "    left_curve_m = np.sqrt((L_x2-xc)*(L_x2-xc)+(y2-yc)*(y2-yc))\n",
    "    \n",
    "    m1 = (y2-y1)/(R_x2-R_x1)\n",
    "    m2 = (y3-y2)/(R_x3-R_x2)\n",
    "    \n",
    "    xc = (m1*m2*(y1-y3)+m2*(R_x1+R_x2)-m1*(R_x2+R_x3))/(2*(m2-m1))\n",
    "    yc = -(xc-(R_x1+R_x2)/2)/m1+(y1+y2)/2\n",
    "    \n",
    "    right_curve_m = np.sqrt((R_x2-xc)*(R_x2-xc)+(y2-yc)*(y2-yc))\n",
    "    \n",
    "    # Calculate the new radii of curvature\n",
    "    curve_m =int((left_curve_m+right_curve_m)/2+0.5)\n",
    "    \n",
    "    left_pos_lane = L_RAN_xplot_m[719]\n",
    "    right_pos_lane = R_RAN_xplot_m[719]\n",
    "    mid_pos_car = 1280/2*xm_per_pix\n",
    "    mid_pos_lane = (left_pos_lane+right_pos_lane)/2\n",
    "    dif_pos_car = int((mid_pos_car-mid_pos_lane)*100+0.5)/100\n",
    "\n",
    "    return curve_m, dif_pos_car"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project the measurement back onto the road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_RAN_meas(undist, left_fitx, right_fitx, ploty, binary_warped, curve_m, dif_pos_car ):\n",
    "# Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    left_fitx = np.ndarray.flatten(left_fitx)\n",
    "    right_fitx =  np.ndarray.flatten(right_fitx)\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp,inv_M, (undist.shape[1], undist.shape[0])) \n",
    "      \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    # put text on the image\n",
    "    text_curve = 'mean curvature = ' + str(curve_m) + 'm'\n",
    "    if dif_pos_car < 0:\n",
    "        text_dif = 'car shift = ' + str(dif_pos_car) + 'm to the left'\n",
    "    else:\n",
    "        text_dif = 'car shift = ' + str(dif_pos_car) + 'm to the right'\n",
    "        \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(result,text_curve,(10,40), font, 1,(255,0,0),2,cv2.LINE_AA)\n",
    "    cv2.putText(result,text_dif,(10,75), font, 1,(255,0,0),2,cv2.LINE_AA) \n",
    "#    plt.imshow(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_meas(undist, left_fit, right_fit, binary_warped, curve_m, dif_pos_car ):\n",
    "# Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])    \n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp,inv_M, (undist.shape[1], undist.shape[0])) \n",
    "\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    # put text on the image\n",
    "    text_curve = 'mean curvature = ' + str(curve_m) + 'm'\n",
    "    if dif_pos_car < 0:\n",
    "        text_dif = 'car shift = ' + str(dif_pos_car) + 'm to the left'\n",
    "    else:\n",
    "        text_dif = 'car shift = ' + str(dif_pos_car) + 'm to the right'\n",
    "        \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(result,text_curve,(10,40), font, 1,(255,0,0),2,cv2.LINE_AA)\n",
    "    cv2.putText(result,text_dif,(10,75), font, 1,(255,0,0),2,cv2.LINE_AA)\n",
    "    \n",
    "#    plt.imshow(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Image Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from __future__ import division\n",
    "\n",
    "os.listdir(\"test_images/\")\n",
    "c_mtx, c_dist = camera_matrix() #return mtx, dist\n",
    "pict_list = os.listdir(\"test_images/\")\n",
    "start = True\n",
    "for pict in pict_list:\n",
    "    img = cv2.imread(\"test_images/\" + pict)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # undistort image\n",
    "    undist_img = cal_undistort(img, c_mtx, c_dist)\n",
    "    \n",
    "##### End Threshold and mask, undistort and warp with different color channels / color spaces\n",
    "    # RGB color space\n",
    "    ### only R channel\n",
    "    R_channel = undist_img[:,:,0]\n",
    "    #R_comb_bin = combined_thresh(R_channel, SOBEL_KERNEL=3, THRESH=(210, 255), MAG_THRESH=(60, 200), DIR_TRESH=(0.7, 1.2))\n",
    "    #R_comb_bin = dir_threshold(channel_tresh(R_channel,CHL_TRESH=(210, 255)), sobel_kernel=3, dir_thresh=(0.7, 1.2))\n",
    "    R_comb_bin = channel_tresh(R_channel,CHL_TRESH=(210, 255)) #best pick\n",
    "    # mask image\n",
    "    msk_R_bin = region_of_interest(R_comb_bin)#.astype(np.float)\n",
    "\n",
    "    # HLS color space \n",
    "    hls = cv2.cvtColor(undist_img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    ### only H channel\n",
    "    h1_channel = hls[:,:,0]\n",
    "    #H_comb_bin = combined_thresh(h1_channel, SOBEL_KERNEL=9, THRESH=(20, 80), MAG_THRESH=(60, 255), DIR_TRESH=(0.7, 1.2))#best pick\n",
    "    H_comb_bin = dir_threshold(channel_tresh(h1_channel,CHL_TRESH=(20, 80)), sobel_kernel=3, dir_thresh=(0.7, 1.2))\n",
    "    #H_comb_bin = channel_tresh(h1_channel,CHL_TRESH=(20, 80))\n",
    "    # mask image\n",
    "    msk_H_bin = region_of_interest(H_comb_bin)\n",
    "\n",
    "    ### only S channel\n",
    "    s1_channel = hls[:,:,2]\n",
    "    #S_comb_bin = combined_thresh(l1_channel, SOBEL_KERNEL=9, THRESH=(85, 255), MAG_THRESH=(60, 200), DIR_TRESH=(0.6, 1.3))\n",
    "    #S_comb_bin = dir_threshold(channel_tresh(s1_channel,CHL_TRESH=(85, 255)), sobel_kernel=3, dir_thresh=(0.6, 1.3))\n",
    "    S_comb_bin = channel_tresh(s1_channel,CHL_TRESH=(85, 255)) #best pick\n",
    "    # mask image\n",
    "    msk_S_bin = region_of_interest(S_comb_bin)\n",
    "    ##### End Threshold and mask    \n",
    "\n",
    "    ### only grayscale cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    G_channel = cv2.cvtColor(undist_img, cv2.COLOR_RGB2GRAY)\n",
    "    G_comb_bin = combined_thresh(G_channel, SOBEL_KERNEL=3, THRESH=(100, 200), MAG_THRESH=(10, 225), DIR_TRESH=(0.7, 1.2))\n",
    "    #G_comb_bin = dir_threshold(channel_tresh(G_channel,CHL_TRESH=(100, 200)), sobel_kernel=3, dir_thresh=(0.7, 1.2))\n",
    "    #G_comb_bin = channel_tresh(G_channel,CHL_TRESH=(100, 200)) #best pick\n",
    "    # mask image\n",
    "    msk_G_bin = region_of_interest(G_comb_bin)#.astype(np.float)\n",
    "\n",
    "    \n",
    "    # LUV color space L* beschreibt die Helligkeitsachse und u*,v* die Farbartebene\n",
    "    Luv = cv2.cvtColor(undist_img, cv2.COLOR_RGB2LUV)\n",
    "    # only L channel\n",
    "    l2_channel = Luv[:,:,0]\n",
    "    #L2_comb_bin = combined_thresh(l2_channel, SOBEL_KERNEL=9, THRESH=(225, 255), MAG_THRESH=(60, 255), DIR_TRESH=(0.7, 1.2))#best pick\n",
    "    #L2_comb_bin = dir_threshold(channel_tresh(l2_channel,CHL_TRESH=(225, 255)), sobel_kernel=3, dir_thresh=(0.7, 1.2))\n",
    "    L2_comb_bin = channel_tresh(l2_channel,CHL_TRESH=(225, 255))\n",
    "    # mask image\n",
    "    msk_L2_bin = region_of_interest(L2_comb_bin)\n",
    "    \n",
    "    # LAB color space L* beschreibt die Helligkeitsachse und u*,v* die Farbartebene\n",
    "    Lab = cv2.cvtColor(undist_img, cv2.COLOR_RGB2Lab)\n",
    "    # only B channel\n",
    "    b3_channel = Lab[:,:,2]\n",
    "    #B3_comb_bin = combined_thresh(b3_channel, SOBEL_KERNEL=9, THRESH=(155, 200), MAG_THRESH=(60, 255), DIR_TRESH=(0.7, 1.2))#best pick\n",
    "    B3_comb_bin = dir_threshold(channel_tresh(b3_channel,CHL_TRESH=(155, 200)), sobel_kernel=3, dir_thresh=(0.7, 1.2))\n",
    "    #B3_comb_bin = channel_tresh(b3_channel,CHL_TRESH=(155, 200))\n",
    "    # mask image\n",
    "    msk_B3_bin = region_of_interest(B3_comb_bin)    \n",
    "   \n",
    "\n",
    "    ##### Add the binary images together\n",
    "    comb_binary = cv2.bitwise_or(msk_S_bin*1.,cv2.bitwise_or(msk_R_bin*1., msk_B3_bin))\n",
    "    top_down, perspective_M , inv_M = img_persp(comb_binary)\n",
    "##### End Threshold and mask, undistort and warp with different color channels / color spaces\n",
    "################# finding pixels with sliding window and RANSAC\n",
    "    if start:\n",
    "        left_fit, right_fit, ploty, out_img, leftx, lefty, rightx, righty = slide_win_poly(top_down, False)\n",
    "#        L_RAN_xplot, R_RAN_xplot, ploty, out_img, leftx, lefty, rightx, righty = slide_win_poly(top_down, False)\n",
    "        start = False\n",
    "    else:\n",
    "        left_fit, right_fit, out_img, leftx, lefty, rightx, righty = nxt_win_poly(top_down,left_fit, right_fit, False)\n",
    "    \n",
    "    y_eval = np.max(ploty)\n",
    "\n",
    "    # Now our radius of curvature is in meters\n",
    "    curve_m, dif_pos_car = meas_curvature_m(leftx, lefty, rightx, righty, y_eval)\n",
    "#    curve_m, dif_pos_car = meas_RAN_curvature_m(leftx, lefty, rightx, righty, y_eval)    \n",
    "      \n",
    "    output = project_meas(undist_img, left_fit, right_fit, top_down, curve_m, dif_pos_car)\n",
    "#    output = project_RAN_meas(undist_img, L_RAN_xplot, R_RAN_xplot,ploty, top_down, curve_m, dif_pos_car)\n",
    "    \n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(undist_img, cmap='gray')\n",
    "    ax1.set_title('Original Image', fontsize=50)\n",
    "    ax2.imshow(output, cmap='gray')\n",
    "    ax2.set_title('Undistorted Output Image', fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class definition\n",
    "For video pipeline I decided to change my code and introduce a class called Line() to make things more easy and to be able to take a mean value over a certain count of frames so that the lane aren't jiggling so  much and give a  smoother output. The other reason was that I can store the previous values and can take those values if the lane detection fails some frames. More or less I used the functions I showed above, just adapted to the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line:\n",
    "    def __init__(self):\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False \n",
    "        self.start = True\n",
    "        self.Lost_frame = 0\n",
    "        self.approx = False\n",
    "        \n",
    "        # x an y values of the lanes in previous frame\n",
    "        self.preX = None\n",
    "        self.preY = None        \n",
    "        self.x_vals = None\n",
    "        self.y_vals = None\n",
    "        self.ploty = None\n",
    "       \n",
    "        #polynomial coefficients current\n",
    "        self.poly_fit0 = None\n",
    "        self.poly_fit1 = None\n",
    "        self.poly_fit2 = None\n",
    "\n",
    "        #polynomial coefficients over the last 30 iterations\n",
    "        self.all_poly_fit0 = deque(maxlen=30)\n",
    "        self.all_poly_fit1 = deque(maxlen=30)\n",
    "        self.all_poly_fit2 = deque(maxlen=30)\n",
    "        self.all_poly_fitx = deque(maxlen=30)\n",
    "        \n",
    "        #polynomial coefficients of the lanes in previous frame\n",
    "        self.pre_poly_fit0 = None\n",
    "        self.pre_poly_fit1 = None\n",
    "        self.pre_poly_fit2 = None\n",
    "        self.pre_poly_fitx = None\n",
    "\n",
    "        #radius of curvature of the line\n",
    "        self.radius_m = None\n",
    "        self.all_rad_m = deque(maxlen=30)\n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.dif_pos_car = None \n",
    "        self.all_dif_pos_car = deque(maxlen=30)\n",
    "        \n",
    "    \n",
    "    ### Implementation of a sliding window and Polynomial Fit\n",
    "    def histo_wind(self, top_down):\n",
    "        top_down2 = (top_down*255).astype(np.uint8)\n",
    "\n",
    "        # Take a histogram of the bottom half of the image\n",
    "        histogram = np.sum(top_down2[int(top_down2.shape[0]/2):,:], axis=0)\n",
    "\n",
    "        # Find the peak of the left and right halves of the histogram\n",
    "        # These will be the starting point for the left and right lines\n",
    "        midpoint = np.int(histogram.shape[0]/2)\n",
    "        if self == Left:\n",
    "            x_base = np.argmax(histogram[:midpoint])\n",
    "        else:\n",
    "            x_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        # Choose the number of sliding windows\n",
    "        nwindows = 9\n",
    "        # Set height of windows\n",
    "        window_height = np.int(top_down.shape[0]/nwindows)\n",
    "        # Identify the x and y positions of all nonzero pixels in the image\n",
    "        nonzero = top_down2.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        \n",
    "        # Set the width of the windows +/- margin\n",
    "        margin = 75\n",
    "        # Set minimum number of pixels found to recenter window\n",
    "        minpix = 50\n",
    "        # Create empty lists to receive left and right lane pixel indices\n",
    "        lane_inds = []\n",
    "        \n",
    "        # Current positions to be updated for each window\n",
    "        x_current = x_base\n",
    "        win_x_low = x_current - margin\n",
    "        win_x_high = x_current + margin        \n",
    "\n",
    "        # Step through the windows one by one\n",
    "        for window in range(nwindows):\n",
    "            # Identify window boundaries in x and y (and right and left)\n",
    "            win_y_low = top_down2.shape[0] - (window+1)*window_height\n",
    "            win_y_high = top_down2.shape[0] - window*window_height\n",
    "\n",
    "            # Identify the nonzero pixels in x and y within the window\n",
    "            good_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_x_low) & (nonzerox < win_x_high)).nonzero()[0]\n",
    "            \n",
    "            if len(good_inds) < 9500:\n",
    "                # Append these indices to the lists\n",
    "                lane_inds.append(good_inds)\n",
    "\n",
    "            # If you found > minpix pixels, recenter next window on their mean position\n",
    "            if len(lane_inds) > minpix:\n",
    "                x_current = np.int(np.mean(nonzerox[lane_inds]))\n",
    "\n",
    "        # Concatenate the arrays of indices\n",
    "        lane_inds = np.concatenate(lane_inds)\n",
    "\n",
    "        # Extract line pixel positions\n",
    "        self.x_vals = nonzerox[lane_inds]\n",
    "        self.y_vals = nonzeroy[lane_inds] \n",
    "        \n",
    "        if np.sum(self.x_vals) > 0:\n",
    "            self.detected = True\n",
    "        else:\n",
    "            self.detected = False\n",
    "            self.x_vals = self.preX\n",
    "            self.y_vals = self.preY\n",
    "        return \n",
    "\n",
    "    \n",
    "    ### Implementation of a sliding window with polynomial coefficients from previous frame and Polynomial Fit    \n",
    "    def nxt_win_poly_cl(self, top_down):\n",
    "        binary_warped= (top_down*255).astype(np.uint8)\n",
    "        out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "\n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        margin = 75\n",
    "        lane_inds = ((nonzerox > (self.pre_poly_fit0*(nonzeroy**2) + self.pre_poly_fit1*nonzeroy + \\\n",
    "                                  self.pre_poly_fit2- margin)) & \\\n",
    "                     (nonzerox < (self.pre_poly_fit0*(nonzeroy**2) + self.pre_poly_fit1*nonzeroy + \\\n",
    "                                  self.pre_poly_fit2 + margin))) \n",
    "\n",
    "        # Extract line pixel positions\n",
    "        self.x_vals = nonzerox[lane_inds]\n",
    "        self.y_vals = nonzeroy[lane_inds] \n",
    "        \n",
    "        if np.sum(self.x_vals) > 0:\n",
    "            self.detected = True\n",
    "        else:\n",
    "            self.detected = False\n",
    "            self.x_vals = self.preX\n",
    "            self.y_vals = self.preY\n",
    "        return\n",
    "    \n",
    "    def poly_appr(self, top_down2):\n",
    "        # Fit a second order polynomial to each\n",
    "        poly_fit = np.polyfit(self.y_vals, self.x_vals, 2)\n",
    "        self.poly_fit0 = poly_fit[0] \n",
    "        self.poly_fit1 = poly_fit[1] \n",
    "        self.poly_fit2 = poly_fit[2]\n",
    "        self.ploty = np.linspace(0, top_down2.shape[0]-1, top_down2.shape[0])\n",
    "        return \n",
    "    \n",
    "    def poly_calc_save(self, damp):\n",
    "\n",
    "        #polynomial coefficients over the last 30 iterations with damping\n",
    "        S_fit0 = np.mean(self.all_poly_fit0) + damp*(self.poly_fit0 - np.mean(self.all_poly_fit0))\n",
    "        S_fit1 = np.mean(self.all_poly_fit1) + damp*(self.poly_fit1 - np.mean(self.all_poly_fit1))\n",
    "        S_fit2 = np.mean(self.all_poly_fit2) + damp*(self.poly_fit2 - np.mean(self.all_poly_fit2))\n",
    "        S_end_poly_fitx = S_fit0*self.ploty**2 + S_fit1*self.ploty +S_fit2\n",
    "        \n",
    "        if damp > 0:\n",
    "            self.poly_fit0 = S_fit0\n",
    "            self.poly_fit1 = S_fit1\n",
    "            self.poly_fit2 = S_fit2\n",
    "\n",
    "            self.all_poly_fit0 = S_fit0\n",
    "            self.all_poly_fit1 = S_fit1\n",
    "            self.all_poly_fit2 = S_fit2\n",
    "\n",
    "            self.pre_poly_fit0 = S_fit0\n",
    "            self.pre_poly_fit1 = S_fit1\n",
    "            self.pre_poly_fit2 = S_fit2\n",
    "            self.pre_poly_fitx = S_end_poly_fitx\n",
    "            \n",
    "        y_eval = np.max(self.ploty)\n",
    "        self.all_rad_m = self.LaR_meas_curvature_m(y_eval)\n",
    "        self.all_dif_pos_car = self.LaR_calc_lane_cl_m(y_eval)\n",
    "        return S_end_poly_fitx\n",
    "    \n",
    "    def save_param_io(self, S_poly_fitx):\n",
    "        self.all_poly_fit0 = self.poly_fit0\n",
    "        self.all_poly_fit1 = self.poly_fit1\n",
    "        self.all_poly_fit2 = self.poly_fit2\n",
    "        self.all_poly_fitx = S_poly_fitx\n",
    "\n",
    "        #polynomial coefficients over the last 20 iterations\n",
    "        self.pre_poly_fit0 = self.poly_fit0\n",
    "        self.pre_poly_fit1 = self.poly_fit1\n",
    "        self.pre_poly_fit2 = self.poly_fit2\n",
    "        self.pre_poly_fitx = S_poly_fitx\n",
    "        self.preX = self.x_vals\n",
    "        self.preY = self.y_vals\n",
    "        y_eval = np.max(self.ploty)\n",
    "        self.all_rad_m = self.LaR_meas_curvature_m(y_eval)\n",
    "        self.all_dif_pos_car = self.LaR_calc_lane_cl_m(y_eval)\n",
    "        return\n",
    "    \n",
    "    def LaR_meas_curvature_m(self, y_eval):\n",
    "        # Define conversions in x and y from pixels space to meters\n",
    "        ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "        # Fit new polynomials to x,y in world space \n",
    "        S_fit_cr = np.polyfit(self.preY*ym_per_pix, self.preX*xm_per_pix, 2)\n",
    "\n",
    "        # Calculate the new radii of curvature\n",
    "        curve_m = ((1 + (2*S_fit_cr[0]*y_eval*ym_per_pix + S_fit_cr[1])**2)**1.5) / np.absolute(2*S_fit_cr[0])\n",
    "        return curve_m\n",
    "\n",
    "    def LaR_calc_lane_cl_m(self, y_eval):\n",
    "        ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "        \n",
    "        S_fit_cr = np.polyfit(self.preY*ym_per_pix, self.preX*xm_per_pix, 2)\n",
    "        \n",
    "        lane_pos = S_fit_cr[0]*(y_eval*ym_per_pix)**2 + S_fit_cr[1]*y_eval*ym_per_pix + S_fit_cr[2]         \n",
    "        return lane_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_meas_cl(undist, left_fitx, right_fitx, ploty, binary_warped, curve_m, dif_pos_car ):\n",
    "# Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(binary_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "#    # Generate x and y values for plotting\n",
    "#    ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0])    \n",
    "#    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "#    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp,inv_M, (undist.shape[1], undist.shape[0])) \n",
    "      \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    # put text on the image\n",
    "    text_curve = 'mean curvature = ' + str(curve_m) + 'm'\n",
    "    if dif_pos_car < 0:\n",
    "        text_dif = 'car shift = ' + str(dif_pos_car) + 'm to the left'\n",
    "    else:\n",
    "        text_dif = 'car shift = ' + str(dif_pos_car) + 'm to the right'\n",
    "        \n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(result,text_curve,(10,40), font, 1,(255,0,0),2,cv2.LINE_AA)\n",
    "    cv2.putText(result,text_dif,(10,75), font, 1,(255,0,0),2,cv2.LINE_AA)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meas_curvature_cl_m(y_eval):\n",
    "          \n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    mid_pos_car = 1280/2*xm_per_pix\n",
    "\n",
    "    left_curve_m = np.mean(Left.all_rad_m)\n",
    "    right_curve_m = np.mean(Right.all_rad_m)\n",
    "    curve_m =int((left_curve_m+right_curve_m)/2+0.5)\n",
    "    \n",
    "    left_pos_lane = np.mean(Left.all_dif_pos_car)\n",
    "    right_pos_lane = np.mean(Right.all_dif_pos_car)\n",
    "    mid_pos_lane = (left_pos_lane+right_pos_lane)/2\n",
    "    dif_pos_car = int((mid_pos_car-mid_pos_lane)*100+0.5)/100  \n",
    "    \n",
    "    return curve_m, dif_pos_car"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Pipeline\n",
    "To get the pipeline robust I add two features:\n",
    "First I introduced the possibility to check which threshold / color space or color channel would be the best pick for lane identification in comparison to the previous calculated polynomial fit. Those threshold are appended to the comb_bin_stack array and used afterwards in the for – loop. This wourld also give the possibility to use different 'sets' for left and right side (a better pre-selection to reduce time in the loop). \n",
    "\n",
    "The measure for the quality of the current lane line detection and the previous polynomial fit is the absolute error between those lines.\n",
    "\n",
    "Having chosen the best binary image combination and calculated the polynomial fit I established a quality check with the calculation of the curve flection with means of the first polynomial coefficient and the position of the lane with the  3rd  polynomial coefficient.\n",
    "\n",
    "Then in the further steps if the position (shift) and the flection is below certain values the current data set is added to the mean value stack without changes. Otherwise a damping value is added or if the values indicate that the identified lane is completely untrustable it's dismissed and the previous values are taken and shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "def process_image(image):\n",
    "    # defining global values\n",
    "    global start\n",
    "    global c_mtx\n",
    "    global c_dist\n",
    "    # convert img to RGB\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # undistort image\n",
    "    undist_img = cal_undistort(img, c_mtx, c_dist)\n",
    "    \n",
    "##### Start Threshold and mask\n",
    "    comb_bin_stack=[]\n",
    "\n",
    "    # RGB color space\n",
    "    ### only R channel\n",
    "    R_channel = undist_img[:,:,0]\n",
    "    #R_comb_bin = combined_thresh(R_channel, SOBEL_KERNEL=3, THRESH=(210, 255), MAG_THRESH=(60, 200), DIR_TRESH=(0.7, 1.2))\n",
    "    #R_comb_bin = dir_threshold(channel_tresh(R_channel,CHL_TRESH=(210, 255)), sobel_kernel=3, dir_thresh=(0.7, 1.2))\n",
    "    R_comb_bin = channel_tresh(R_channel,CHL_TRESH=(210, 255)) #best pick\n",
    "    # mask image\n",
    "    msk_R_bin = region_of_interest(R_comb_bin)#.astype(np.float)\n",
    "    comb_bin_stack.append(msk_R_bin*1.)\n",
    "\n",
    "    ### only grayscale cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    G_channel = cv2.cvtColor(undist_img, cv2.COLOR_RGB2GRAY)\n",
    "    G_comb_bin = combined_thresh(G_channel, SOBEL_KERNEL=3, THRESH=(100, 200), MAG_THRESH=(10, 225), DIR_TRESH=(0.7, 1.2))\n",
    "    #G_comb_bin = dir_threshold(channel_tresh(G_channel,CHL_TRESH=(100, 200)), sobel_kernel=3, dir_thresh=(0.7, 1.2))\n",
    "    #G_comb_bin = channel_tresh(G_channel,CHL_TRESH=(100, 200)) #best pick\n",
    "    # mask image\n",
    "    msk_G_bin = region_of_interest(G_comb_bin)#.astype(np.float)\n",
    "    comb_bin_stack.append(msk_G_bin)\n",
    "    \n",
    "    # HLS color space \n",
    "    hls = cv2.cvtColor(undist_img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    ### only H channel\n",
    "    h1_channel = hls[:,:,0]\n",
    "    #H_comb_bin = combined_thresh(h1_channel, SOBEL_KERNEL=9, THRESH=(20, 80), MAG_THRESH=(60, 255), DIR_TRESH=(0.7, 1.2))#best pick\n",
    "    H_comb_bin = dir_threshold(channel_tresh(h1_channel,CHL_TRESH=(20, 80)), sobel_kernel=3, dir_thresh=(0.7, 1.2))\n",
    "    #H_comb_bin = channel_tresh(h1_channel,CHL_TRESH=(20, 80))\n",
    "    # mask image\n",
    "    msk_H_bin = region_of_interest(H_comb_bin)\n",
    "    comb_bin_stack.append(msk_H_bin*1.)\n",
    "    \n",
    "    ### only S channel\n",
    "    s1_channel = hls[:,:,2]\n",
    "    #S_comb_bin = combined_thresh(l1_channel, SOBEL_KERNEL=9, THRESH=(85, 255), MAG_THRESH=(60, 200), DIR_TRESH=(0.6, 1.3))\n",
    "    #S_comb_bin = dir_threshold(channel_tresh(s1_channel,CHL_TRESH=(85, 255)), sobel_kernel=3, dir_thresh=(0.6, 1.3))\n",
    "    S_comb_bin = channel_tresh(s1_channel,CHL_TRESH=(85, 255)) #best pick\n",
    "    # mask image\n",
    "    msk_S_bin = region_of_interest(S_comb_bin)\n",
    "    ##### End Threshold and mask \n",
    "    comb_bin_stack.append(msk_S_bin*1.)\n",
    "  \n",
    "    # LUV color space L* beschreibt die Helligkeitsachse und u*,v* die Farbartebene\n",
    "    Luv = cv2.cvtColor(undist_img, cv2.COLOR_BGR2LUV)\n",
    "    # only L channel\n",
    "    l2_channel = Luv[:,:,0]\n",
    "    #L2_comb_bin = combined_thresh(l2_channel, SOBEL_KERNEL=9, THRESH=(225, 255), MAG_THRESH=(60, 255), DIR_TRESH=(0.7, 1.2))#best pick\n",
    "    #L2_comb_bin = dir_threshold(channel_tresh(l2_channel,CHL_TRESH=(225, 255)), sobel_kernel=3, dir_thresh=(0.7, 1.2))\n",
    "    L2_comb_bin = channel_tresh(l2_channel,CHL_TRESH=(225, 255))\n",
    "    # mask image\n",
    "    msk_L2_bin = region_of_interest(L2_comb_bin)\n",
    "    comb_bin_stack.append(msk_L2_bin*1.)\n",
    "    \n",
    "    # LAB color space L* beschreibt die Helligkeitsachse und u*,v* die Farbartebene\n",
    "    Lab = cv2.cvtColor(undist_img, cv2.COLOR_BGR2Lab)\n",
    "    # only B channel\n",
    "    b3_channel = Lab[:,:,2]\n",
    "    #B3_comb_bin = combined_thresh(b3_channel, SOBEL_KERNEL=9, THRESH=(155, 200), MAG_THRESH=(60, 255), DIR_TRESH=(0.7, 1.2))#best pick\n",
    "    B3_comb_bin = dir_threshold(channel_tresh(b3_channel,CHL_TRESH=(155, 200)), sobel_kernel=3, dir_thresh=(0.7, 1.2))\n",
    "    #B3_comb_bin = channel_tresh(b3_channel,CHL_TRESH=(155, 200))\n",
    "    # mask image\n",
    "    msk_B3_bin = region_of_interest(B3_comb_bin) \n",
    "    comb_bin_stack.append(msk_B3_bin*1.)\n",
    "    \n",
    "    ##### Add the binary images together\n",
    "\n",
    "#    comb_binary = cv2.bitwise_or(msk_R_bin*1.,cv2.bitwise_or(msk_S_bin, msk_H_bin))\n",
    "\n",
    "    R_comb_bin_stack = comb_bin_stack\n",
    "\n",
    "########## identify pixels in binary image - calculate polynoms for left and right side\n",
    "## Left side\n",
    "    if Left.start == True:\n",
    "        img = comb_bin_stack[1]\n",
    "\n",
    "        top_down, perspective_M , inv_M = img_persp(img)    \n",
    "        Left.histo_wind(top_down)    \n",
    "        Left.poly_appr(top_down)\n",
    "        L_poly_fitx =  Left.poly_fit0*Left.ploty**2 + Left.poly_fit1*Left.ploty+Left.poly_fit2\n",
    "        Left.save_param_io(L_poly_fitx)      \n",
    "        L_end_poly_fitx = L_poly_fitx      \n",
    "        Left.start = False\n",
    "    else:\n",
    "        # choose best binary image (combination) for the current situation\n",
    "        # comparing to the previous polynom\n",
    "        L_best_pick_error = 1000.        \n",
    "        L_Img_best_pick = comb_bin_stack[-1]        \n",
    "        for img in comb_bin_stack:\n",
    "            top_down, perspective_M , inv_M = img_persp(img)\n",
    "            if Left.approx == True: # perform search with previous polynom\n",
    "                Left.nxt_win_poly_cl(top_down)        \n",
    "            if Left.approx == False: # perform search with histogram\n",
    "                Left.histo_wind(top_down)        \n",
    "            Left.poly_appr(top_down)        \n",
    "            L_poly_fitx =  Left.poly_fit0*Left.ploty**2 + Left.poly_fit1*Left.ploty+Left.poly_fit2\n",
    "            L_all_poly_fitx = np.mean(Left.all_poly_fit0)*Left.ploty**2 + np.mean(Left.all_poly_fit1)*Left.ploty \\\n",
    "                            +np.mean(Left.all_poly_fit2)\n",
    "            L_all_abs_err = mean_absolute_error(L_all_poly_fitx, L_poly_fitx)\n",
    "            if L_all_abs_err < L_best_pick_error and Left.detected == True:\n",
    "                L_best_pick_error = L_all_abs_err\n",
    "                L_Img_best_pick = img\n",
    "\n",
    "        ################# finding pixels with sliding window and polyfit and the best pick image               \n",
    "        if Left.approx == True: # perform search with previous polynom\n",
    "            top_down1, perspective_M , inv_M = img_persp(L_Img_best_pick)\n",
    "            Left.nxt_win_poly_cl(top_down1)\n",
    "        if Left.approx == False: # perform search with histogram\n",
    "            top_down1, perspective_M , inv_M = img_persp(L_Img_best_pick)\n",
    "            Left.histo_wind(top_down1)            \n",
    "        Left.poly_appr(top_down1)            \n",
    "        # calculate the current polynom with the best fitting binary image\n",
    "        L_poly_fitx =  Left.poly_fit0*Left.ploty**2 + Left.poly_fit1*Left.ploty+Left.poly_fit2       \n",
    "        L_all_poly_fitx = np.mean(Left.all_poly_fit0)*Left.ploty**2 + np.mean(Left.all_poly_fit1)*Left.ploty \\\n",
    "                            +np.mean(Left.all_poly_fit2)\n",
    "        L_pre_poly_fitx = Left.pre_poly_fitx\n",
    "        # 1. calculate error\n",
    "        L_pre_abs_err = mean_absolute_error(L_pre_poly_fitx, L_poly_fitx)\n",
    "        L_all_abs_err = mean_absolute_error(L_all_poly_fitx, L_poly_fitx)\n",
    "        # 2. check quality of curvature lh / rh with pre\n",
    "        L_flect_current = Left.poly_fit0\n",
    "        L_flect_all = np.mean(Left.all_poly_fit0)\n",
    "        dif_L_Flect = abs(L_flect_current-L_flect_all)\n",
    "        # 3. check quality of lane position lh / rh with pre        \n",
    "        L_shift_current = Left.poly_fit2\n",
    "        L_shift_all = np.mean(Left.all_poly_fit2)\n",
    "        dif_L_shift = abs(L_shift_current-L_shift_all)\n",
    "        \n",
    "        y_eval = np.max(Left.ploty)        \n",
    "        # if certain value are not reached - everything is fine - add date \n",
    "        if dif_L_shift < 50 and (dif_L_Flect*1.e+5) < 7.:\n",
    "            Left.Lost_frame =0\n",
    "            damp = 1.\n",
    "            L_end_poly_fitx = Left.poly_calc_save(damp)\n",
    "            # pixels in next frame can be detected with polynom\n",
    "            Left.approx = True\n",
    "        else:\n",
    "            # if values are not quite as good introduce the value with damping\n",
    "            # better search for pixels in next frame with histogram\n",
    "            Left.approx = False\n",
    "            if dif_L_shift < 150 and (dif_L_Flect*1.e+5) < 12.:\n",
    "                damp = 0.05\n",
    "            # else if values are worse take the previous values\n",
    "            else:\n",
    "                damp = 0\n",
    "            Left.Lost_frame +=1\n",
    "            if Left.Lost_frame > 8:              \n",
    "                Left.Lost_frame =0\n",
    "            L_end_poly_fitx = Left.poly_calc_save(damp)        \n",
    "\n",
    "########## Right side            \n",
    "    if Right.start == True:\n",
    "        img = R_comb_bin_stack[0]\n",
    "\n",
    "        top_down, perspective_M , inv_M = img_persp(img)\n",
    "        Right.histo_wind(top_down)         \n",
    "        Right.poly_appr(top_down)\n",
    "        R_poly_fitx =  Right.poly_fit0*Right.ploty**2 + Right.poly_fit1*Right.ploty+Right.poly_fit2        \n",
    "        Right.save_param_io(R_poly_fitx)\n",
    "        R_end_poly_fitx = R_poly_fitx            \n",
    "        Right.start = False\n",
    "    else:\n",
    "        # choose best binary image (combination) for the current situation\n",
    "        # comparing to the previous polynom\n",
    "        R_best_pick_error = 1000.\n",
    "        R_Img_best_pick = R_comb_bin_stack[0]\n",
    "        for img in R_comb_bin_stack:\n",
    "            top_down, perspective_M , inv_M = img_persp(img)\n",
    "        ################# finding pixels with sliding window and polyfit\n",
    "            if Right.approx == True: # perform search with previous polynom  \n",
    "                Right.nxt_win_poly_cl(top_down)    \n",
    "            if Right.approx == False: # perform search with histogram\n",
    "                Right.histo_wind(top_down)      \n",
    "            Right.poly_appr(top_down)\n",
    "            R_poly_fitx =  Right.poly_fit0*Right.ploty**2 + Right.poly_fit1*Right.ploty+Right.poly_fit2        \n",
    "            R_all_poly_fitx = np.mean(Right.all_poly_fit0)*Right.ploty**2 + np.mean(Right.all_poly_fit1)*Right.ploty \\\n",
    "                            +np.mean(Right.all_poly_fit2) \n",
    "            R_all_abs_err = mean_absolute_error(R_all_poly_fitx, R_poly_fitx)\n",
    "            if R_all_abs_err < R_best_pick_error and Right.detected == True:\n",
    "                R_best_pick_error = R_all_abs_err\n",
    "                R_Img_best_pick = img\n",
    "                \n",
    "        ################# finding pixels with sliding window and polyfit and the best pick image               \n",
    "        if Right.approx == True: # perform search with previous polynom\n",
    "            top_down2, perspective_M , inv_M = img_persp(R_Img_best_pick)\n",
    "            Right.nxt_win_poly_cl(top_down2)    \n",
    "        if Right.approx == False: # perform search with histogram\n",
    "            top_down2, perspective_M , inv_M = img_persp(R_Img_best_pick)\n",
    "            Right.histo_wind(top_down2)      \n",
    "        Right.poly_appr(top_down2)\n",
    "        # calculate the current polynom with the best fitting binary image        \n",
    "        R_poly_fitx =  Right.poly_fit0*Right.ploty**2 + Right.poly_fit1*Right.ploty+Right.poly_fit2       \n",
    "        R_all_poly_fitx = np.mean(Right.all_poly_fit0)*Right.ploty**2 + np.mean(Right.all_poly_fit1)*Right.ploty \\\n",
    "                            +np.mean(Right.all_poly_fit2)\n",
    "        R_pre_poly_fitx = Right.pre_poly_fitx\n",
    "        # 1. calculate error        \n",
    "        R_pre_abs_err = mean_absolute_error(R_pre_poly_fitx, R_poly_fitx)\n",
    "        R_all_abs_err = mean_absolute_error(R_all_poly_fitx, R_poly_fitx)                \n",
    "        # 2. check quality of curvature lh / rh with pre\n",
    "        R_flect_current = Right.poly_fit0\n",
    "        R_flect_all = np.mean(Right.all_poly_fit0)\n",
    "        dif_R_Flect = abs(R_flect_current-R_flect_all)\n",
    "        # 3. check quality of lane position lh / rh with pre        \n",
    "        R_shift_current = Right.poly_fit2\n",
    "        R_shift_all = np.mean(Right.all_poly_fit2)\n",
    "        dif_R_shift = abs(R_shift_current-R_shift_all)\n",
    "        y_eval = np.max(Right.ploty)\n",
    "        # if certain values are not reached - everything is fine - add date \n",
    "        if dif_R_shift < 50 and (dif_R_Flect*1.e+5) < 7.:\n",
    "            damp = 1.\n",
    "            Right.Lost_frame =0\n",
    "            R_end_poly_fitx = Right.poly_calc_save(damp)\n",
    "            # pixels in next frame can be detected with polynom\n",
    "            Right.approx = True\n",
    "        else:\n",
    "            # if values are not quite as good introduce the value with damping\n",
    "            # better search for pixels in next frame with histogram\n",
    "            Right.approx = False\n",
    "            if dif_R_shift < 150 and (dif_R_Flect*1.e+5) < 15.:\n",
    "                damp = 0.15\n",
    "            # else if values are worse take the previous values\n",
    "            else:\n",
    "                damp = 0\n",
    "            Right.Lost_frame +=1\n",
    "            if Right.Lost_frame > 10:\n",
    "                Right.Lost_frame = 0\n",
    "            R_end_poly_fitx = Right.poly_calc_save(damp)\n",
    "################# end finding pixels with sliding window and polyfit\n",
    "    \n",
    "################# calculating curvature and position    \n",
    "    y_eval = np.max(Left.ploty)\n",
    "    curve_m, dif_pos_car = meas_curvature_cl_m(y_eval)\n",
    "    output = project_meas_cl(undist_img, L_end_poly_fitx, R_end_poly_fitx, Left.ploty, top_down, curve_m, dif_pos_car )\n",
    "\n",
    "###################################################################\n",
    "    # convert frame back to BGR\n",
    "    output = cv2.cvtColor(output, cv2.COLOR_RGB2BGR)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = True\n",
    "Right = Line()\n",
    "Left = Line()\n",
    "c_mtx, c_dist = camera_matrix() #return mtx, dist\n",
    "project_output = 'P4_adv_lane_lines_challenge_video_001.mp4'\n",
    "#clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "project_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time project_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play the video inline, or if you prefer find the video in your filesystem (should be in the same directory) and play it in your video player of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"1280\" height=\"720\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_output))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
