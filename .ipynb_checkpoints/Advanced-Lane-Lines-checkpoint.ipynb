{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Driving Car Engineer Nanodegree\n",
    "\n",
    "### Advanced Lane Finding Project\n",
    "\n",
    "#### The goals / steps of this project are the following:\n",
    "\n",
    "1. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "1. Apply a distortion correction to raw images.\n",
    "1. Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "1. Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "1. Detect lane pixels and fit to find the lane boundary.\n",
    "1. Determine the curvature of the lane and vehicle position with respect to center.\n",
    "1. Warp the detected lane boundaries back onto the original image.\n",
    "1. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing some useful packages\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "import collections\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that applies Sobel x or y, \n",
    "# then takes an absolute value and applies a threshold.\n",
    "# Note: calling your function with orient='x', thresh_min=5, thresh_max=100\n",
    "# should produce output like the example image shown above this quiz.\n",
    "def abs_sobel_thresh(img, sobel_kernel=3, orient='x', thresh= (0,255)):\n",
    "\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize = sobel_kernel)\n",
    "    else:\n",
    "        sobel = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize = sobel_kernel)\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return sxbinary\n",
    "\n",
    "# Define a function that applies Sobel x and y, \n",
    "# then computes the magnitude of the gradient\n",
    "# and applies a threshold\n",
    "def mag_thresh(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize = sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize = sobel_kernel)\n",
    "    # 3) Calculate the magnitude \n",
    "    sobel_mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*sobel_mag/np.max(sobel_mag))\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= mag_thresh[0]) & (scaled_sobel <= mag_thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return sxbinary\n",
    "\n",
    "# Define a function that applies Sobel x and y, \n",
    "# then computes the direction of the gradient\n",
    "# and applies a threshold.\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "\n",
    "    # Apply the following steps to img\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "# Define a function that thresholds the S-channel of HLS\n",
    "# Use exclusive lower bound (>) and inclusive upper (<=)\n",
    "def s_select(img, thresh=(0, 255)):\n",
    "    # 1) Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s = hls[:,:,2]\n",
    "    \n",
    "    # 2) Apply a threshold to the S channel\n",
    "    binary_output = np.zeros_like(s)\n",
    "    binary_output[(s > thresh[0]) & (s <= thresh[1])] = 1\n",
    "    # 3) Return a binary image of threshold result\n",
    "    return binary_output\n",
    "\n",
    "# Define a function that thresholds the h-channel of HLS\n",
    "# Use exclusive lower bound (>) and inclusive upper (<=)\n",
    "def h_select(img, thresh=(0, 255)):\n",
    "    # 1) Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    h = hls[:,:,0]\n",
    "    \n",
    "    # 2) Apply a threshold to the h channel\n",
    "    binary_output = np.zeros_like(h)\n",
    "    binary_output[(h > thresh[0]) & (h <= thresh[1])] = 1\n",
    "    # 3) Return a binary image of threshold result\n",
    "    return binary_output\n",
    "\n",
    "# Define a function that takes in chessboard size, paths to open/save images \n",
    "# and returns objpoints/imgpoints to undistort an image.\n",
    "def camera_calibrate(chessboard_size, open_path, save_path):\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    i = chessboard_size[0]\n",
    "    j = chessboard_size[1]\n",
    "    objp = np.zeros((i*j,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:i, 0:j].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob(open_path) # camera_cal/calibration*.jpg\n",
    "    count = 0 # placeholder for counting problematic chessboard images, whose corners are not found\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for idx, fname in enumerate(images):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            # Draw and store images whose corners are found\n",
    "            cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "            write_name = save_path+'corners_found'+str(idx + 1)+'.jpg'\n",
    "            cv2.imwrite(write_name, img)\n",
    "        else:\n",
    "            count += 1\n",
    "   # print(\"There are \" + str(count) + \" image/s whose corners couldn't be found.\")\n",
    "    return objpoints, imgpoints\n",
    "\n",
    "# Define a function that undistorts an image\n",
    "def undistort_img(img, objpoints, imgpoints):\n",
    "    h, w = img.shape[:2]\n",
    "    # Do camera calibration given object points and image points\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (w,h), None, None)\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return dst\n",
    "\n",
    "# Performs perspective transform of given image\n",
    "def perspective_trans(img):\n",
    "    sizex = img.shape[0] # 720\n",
    "    sizey = img.shape[1] # 1280\n",
    "    src = np.float32([[588,470], [245,719], [1142, 719],[734,470]])\n",
    "    dst = np.float32([[320,0], [320,720], [960, 720],[960,0]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    warped = cv2.warpPerspective(img, M, (sizey, sizex), flags=cv2.INTER_LINEAR)\n",
    "    #gray = (0.2989*warped[:,:,0] + 0.5870*warped[:,:,1] + 0.1140*warped[:,:,2])/3.0\n",
    "    return {'warped':warped, 'dst':dst, 'src':src, 'Minv': Minv}\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "# Evaluates curvature and offset for given frame using sliding window method\n",
    "def curvature_eval(binary_warped, nwindows = 20, margin = 50, minpix = 50):\n",
    "    # Assuming you have created a warped binary image called \"binary_warped\"\n",
    "    # nwindows = the number of sliding windows\n",
    "    # margin = width of the windows +/- margin\n",
    "    # minpix = minimum number of pixels found to recenter window\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\\\n",
    "                          (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\\\n",
    "                           (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30.0/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    \n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    \n",
    "    # Calculate radii of curvature\n",
    "    y_eval = binary_warped.shape[0] - 1 # position at which curvature is calculated\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    # Calculate offset of car assuming dashcam is mounted at car centerline\n",
    "    offset_val = xm_per_pix * 0.5 * (binary_warped.shape[1] - (leftx_base + rightx_base))\n",
    "    \n",
    "    if offset_val < 0:\n",
    "        offset_dir = 'left'\n",
    "    else:\n",
    "        offset_dir = 'right'\n",
    "    offset = {'offset_val':offset_val, 'offset_dir':offset_dir}\n",
    "    \n",
    "    return {'left_fit':left_fit,'right_fit':right_fit, 'nonzerox':nonzerox,'nonzeroy':nonzeroy,\\\n",
    "            'left_lane_inds':left_lane_inds,'right_lane_inds':right_lane_inds,\\\n",
    "            'left_curverad':left_curverad, 'right_curverad':right_curverad,\\\n",
    "            'right_fit_cr':right_fit_cr,'offset':offset, 'out_img':out_img }\n",
    "\n",
    "# Projects the identified lane lines back down to the road\n",
    "def map_color(Minv, warped, undist, left_fitx, right_fitx, ploty):\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "    return result\n",
    "\n",
    "# Define a function that takes curvature, offset and maps them onto a frame\n",
    "def map_curv(img, curvature, offset):\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX;\n",
    "    offset_val = offset['offset_val']\n",
    "    offset_dir = offset['offset_dir']\n",
    "    curv_text = 'Radius of curvature is: ' + str(curvature) + ' m' \n",
    "    offset_text = 'Car is offset: ' + str(abs(offset_val)) + ' m towards ' + offset_dir\n",
    "    cv2.putText(img, curv_text, (50, 50), font, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(img, offset_text, (50, 100), font, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    return img               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_path = 'camera_cal/calibration*.jpg'\n",
    "save_path = 'camera_cal/'\n",
    "chessboard_size = [9, 6]\n",
    "objpoints = []\n",
    "imgpoints = []\n",
    "objpoints, imgpoints = camera_calibrate(chessboard_size, open_path, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calib3_img = mpimg.imread('camera_cal/calibration1.jpg')\n",
    "calib3_und_img = undistort_img(calib3_img, objpoints, imgpoints)\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(calib3_img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(calib3_und_img)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline (single image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 1. Undistort image\n",
    "# load test image to undistort\n",
    "load_path = 'test_images/test' + str(random.randint(1,6)) + '.jpg'\n",
    "img = mpimg.imread(load_path)\n",
    "und_img = undistort_img(img, objpoints, imgpoints)\n",
    "# Visualize undistortion\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(und_img)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Step 2. Create a thresholded binary image\n",
    "ksize = 5 # Sobel kernel size, choose a larger odd number to smooth gradient measurements\n",
    "img = und_img\n",
    "# Apply each of the thresholding functions\n",
    "gradx = abs_sobel_thresh(img, orient='x', sobel_kernel=ksize, thresh=(20, 100))\n",
    "mag_binary = mag_thresh(img, sobel_kernel=ksize, mag_thresh=(50, 100))\n",
    "s_binary = s_select(img, thresh=(150, 255))\n",
    "combined = np.zeros_like(gradx)\n",
    "combined[(((gradx == 1) & (mag_binary == 1))| (s_binary == 1))] = 1\n",
    "\n",
    "# Plot the result\n",
    "f, ax = plt.subplots(1,1, figsize=(16, 7))\n",
    "ax.imshow(combined, cmap='gray')\n",
    "ax.set_title('Thresholded Magnitude', fontsize=20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Perform a perspective transform\n",
    "img = und_img\n",
    "persp_obj = perspective_trans(img)\n",
    "warped = persp_obj['warped']\n",
    "dst = persp_obj['dst']\n",
    "src = persp_obj['src']\n",
    "Minv = persp_obj['Minv'] # save for use in step 6\n",
    "\n",
    "pts1 = np.array(src, np.int32)\n",
    "pts1 = pts1.reshape((-1,1,2))\n",
    "cv2.polylines(img,[pts1],True,(255,0,0),3)\n",
    "\n",
    "pts2 = np.array(dst, np.int32)\n",
    "pts2 = pts2.reshape((-1,1,2))\n",
    "cv2.polylines(warped,[pts2],True,(255,0,0),3)\n",
    "\n",
    "# Visualize perspective transform\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(warped)\n",
    "ax2.set_title('After Perspective Transform', fontsize=30)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4. Find lane line pixels in a binary warped image and fit 2nd order polynomial\n",
    "# Step 5. Find radius of curvature and offset of vehicle from lane centerline\n",
    "pers_obj2 = perspective_trans(combined)\n",
    "binary_warped = pers_obj2['warped']\n",
    "curv_obj = curvature_eval(binary_warped, nwindows = 30, margin = 40, minpix = 40)\n",
    "left_fit = curv_obj['left_fit']\n",
    "right_fit = curv_obj['right_fit']\n",
    "nonzerox = curv_obj['nonzerox']\n",
    "nonzeroy = curv_obj['nonzeroy']\n",
    "left_lane_inds = curv_obj['left_lane_inds']\n",
    "right_lane_inds = curv_obj['right_lane_inds']\n",
    "offset = curv_obj['offset']\n",
    "out_img = curv_obj['out_img']\n",
    "curvature = 0.5 * (curv_obj['left_curverad'] + curv_obj['right_curverad'])\n",
    "print('The radius of curvature is: ' + str(curvature))\n",
    "print('The car is offset ' + str(offset['offset_val']) + ' towards ' + offset['offset_dir'] + '.')\n",
    "\n",
    "# Generate x and y values for plotting\n",
    "ploty = np.linspace(0, binary_warped.shape[0]-1, binary_warped.shape[0] )\n",
    "left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (18,9))\n",
    "ax1.imshow(binary_warped, cmap = 'gray')\n",
    "ax1.set_title('Binary warped bird\\'s eye view', fontsize = 20)\n",
    "ax2.imshow(out_img)\n",
    "ax2.plot(left_fitx, ploty, color='yellow')\n",
    "ax2.plot(right_fitx, ploty, color='yellow')\n",
    "ax2.set_title('Lane lines identified', fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6. Overlay identified lane on original image\n",
    "plt.imshow(map_color(Minv, binary_warped, und_img, left_fitx, right_fitx, ploty))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline (video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(img, M_inv=Minv, obj_points=objpoints, img_points=imgpoints, ksize=5, nwindows=40, margin=40, minpix=40):\n",
    "    # Step 1. Undistort image\n",
    "    und_img = undistort_img(img, obj_points, img_points) \n",
    "    # Step 2. Apply each of the thresholding functions\n",
    "    gradx = abs_sobel_thresh(und_img, orient='x', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    mag_binary = mag_thresh(und_img, sobel_kernel=ksize, mag_thresh=(50, 100))\n",
    "    s_binary = s_select(und_img, thresh=(150, 255))\n",
    "    combined = np.zeros_like(gradx)\n",
    "    combined[(((gradx == 1) & (mag_binary == 1))| (s_binary == 1))] = 1\n",
    "    # Step 3. Perform a perspective transform\n",
    "    persp_obj = perspective_trans(combined)\n",
    "    warped = persp_obj['warped']\n",
    "    Minv = persp_obj['Minv']\n",
    "    # Step 4. Find lane line pixels in a binary warped image and fit 2nd order polynomial\n",
    "    # Step 5. Find radius of curvature and offset of vehicle from lane centerline\n",
    "    curv_obj = curvature_eval(warped, 40, 40, 40)\n",
    "    left_fit = curv_obj['left_fit']\n",
    "    right_fit = curv_obj['right_fit']\n",
    "    left_lane_inds = curv_obj['left_lane_inds']\n",
    "    right_lane_inds = curv_obj['right_lane_inds']\n",
    "    offset = curv_obj['offset']\n",
    "    left_curverad = curv_obj['left_curverad']\n",
    "    right_curverad = curv_obj['right_curverad']\n",
    "    curvature = 0.5 * (curv_obj['left_curverad'] + curv_obj['right_curverad'])\n",
    "    # Step 6. Overlay identified lane on original image\n",
    "    ploty = np.linspace(0, warped.shape[0]-1, warped.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    lane_img = map_color(M_inv, warped, und_img, left_fitx, right_fitx, ploty)\n",
    "    lane_img = map_curv(lane_img, curvature, offset)\n",
    "    return {'left_fit':left_fit, 'right_fit':right_fit, 'lane_img':lane_img, \\\n",
    "            'offset':offset, 'curvature':curvature, 'left_lane_inds':left_lane_inds,\\\n",
    "            'right_lane_inds':right_lane_inds, 'left_curverad':left_curverad,\\\n",
    "            'right_curverad':right_curverad, 'warped':warped, 'ploty':ploty, 'M_inv':M_inv, 'und_img':und_img}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyVideoProcessor(object):\n",
    "\n",
    "    # constructor function\n",
    "    def __init__(self):\n",
    "        # frame count\n",
    "        self.count = 0\n",
    "        # values of the last 10 fits of the line\n",
    "        self.past_frames_left = collections.deque(maxlen=10)\n",
    "        self.past_frames_right = collections.deque(maxlen=10)\n",
    "\n",
    "        # values of fits of the line for previous frame\n",
    "        self.last_fit_left = []\n",
    "        self.last_fit_right = []\n",
    "\n",
    "        # curvature for previous frame\n",
    "        self.left_curverad = []\n",
    "        self.right_curverad = []\n",
    "        self.curvature = []\n",
    "        \n",
    "        # offset for previous frame\n",
    "        self.offset = []\n",
    "        \n",
    "        # polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit_left = None \n",
    "        self.best_fit_right = None \n",
    "\n",
    "    def pipeline_function(self, frame):\n",
    "        # your lane detection pipeline\n",
    "        if self.count < 10:\n",
    "            pipeline = process_img(frame)\n",
    "            self.past_frames_left.append(pipeline['left_fit'])\n",
    "            self.past_frames_right.append(pipeline['right_fit'])\n",
    "            if self.count == 9:\n",
    "                self.last_fit_left = pipeline['left_fit']\n",
    "                self.last_fit_right = pipeline['right_fit']\n",
    "                self.left_curverad = pipeline['left_curverad']\n",
    "                self.right_curverad = pipeline['right_curverad']\n",
    "                self.curvature = pipeline['curvature']\n",
    "                self.offset = pipeline['offset']\n",
    "                self.best_fit_left = np.mean(self.past_frames_left, axis = 0)\n",
    "                self.best_fit_right = np.mean(self.past_frames_right, axis = 0)\n",
    "            self.count += 1\n",
    "            return pipeline['lane_img']\n",
    "        \n",
    "        else:\n",
    "            # retrieve stored vals from previous frame\n",
    "            previous_left_fit = self.last_fit_left\n",
    "            previous_right_fit = self.last_fit_right\n",
    "            previous_left_curv = self.left_curverad\n",
    "            previous_right_curv = self.right_curverad\n",
    "            previous_curvature = self.curvature\n",
    "            previous_offset = self.offset\n",
    "            avg_left_fit = self.best_fit_left\n",
    "            avg_right_fit = self.best_fit_right\n",
    "            y_delx = frame.shape[0] - 1\n",
    "            prev_delx = abs(avg_left_fit[0]*y_delx**2 + avg_left_fit[1]*y_delx + avg_left_fit[2] \\\n",
    "            - avg_right_fit[0]*y_delx**2 + avg_right_fit[1]*y_delx + avg_right_fit[2])\n",
    "            \n",
    "            # process and evaluate vals for current frame\n",
    "            pipeline = process_img(frame)\n",
    "            und_img = pipeline['und_img']\n",
    "            current_left_fit = pipeline['left_fit']\n",
    "            current_right_fit = pipeline['right_fit']\n",
    "            current_left_curv = pipeline['left_curverad']\n",
    "            current_right_curv = pipeline['right_curverad']\n",
    "            current_curvature = pipeline['curvature']\n",
    "            current_offset = pipeline['offset']\n",
    "            current_delx = abs(current_left_fit[0]*y_delx**2 + current_left_fit[1]*y_delx + current_left_fit[2] \\\n",
    "            - current_right_fit[0]*y_delx**2 + current_right_fit[1]*y_delx + current_right_fit[2])         \n",
    "#             print(current_delx)\n",
    "#             print(abs(current_curvature))\n",
    "#             print(current_left_fit.shape[0])\n",
    "#             print(current_right_fit.shape[0])\n",
    "            \n",
    "            # perform sanity checks\n",
    "            if (current_left_fit.shape[0] == 0) | (current_right_fit.shape[0] == 0) | \\\n",
    "             (abs(current_curvature) > 10000) | (abs(current_curvature) < 800) | (current_delx > 1550) | (current_delx < 1100):\n",
    "                current_left_fit = avg_left_fit\n",
    "                current_right_fit = avg_right_fit\n",
    "                current_curvature = previous_curvature\n",
    "                current_offset = previous_offset\n",
    "                \n",
    "            self.past_frames_left.append(current_left_fit)\n",
    "            self.past_frames_right.append(current_right_fit)\n",
    "            current_avg_left_fit = np.mean(self.past_frames_left, axis = 0)\n",
    "            current_avg_right_fit = np.mean(self.past_frames_right, axis = 0) \n",
    "            self.best_fit_left = current_avg_left_fit \n",
    "            self.best_fit_right = current_avg_right_fit\n",
    "            self.curvature = current_curvature\n",
    "            self.offset = current_offset\n",
    "            \n",
    "            M_inv = pipeline['M_inv']\n",
    "            warped = pipeline['warped']\n",
    "            ploty = pipeline['ploty']\n",
    "            left_fitx = current_avg_left_fit[0]*ploty**2 + current_avg_left_fit[1]*ploty + current_avg_left_fit[2]\n",
    "            right_fitx = current_avg_right_fit[0]*ploty**2 + current_avg_right_fit[1]*ploty + current_avg_right_fit[2]\n",
    "            lane_img = map_color(M_inv, warped, und_img, left_fitx, right_fitx, ploty)\n",
    "            lane_img = map_curv(lane_img, current_curvature, current_offset)\n",
    "            self.count += 1\n",
    "            return lane_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "process_img_obj = process_img(img, Minv, objpoints, imgpoints, 5, 40, 40, 40)\n",
    "plt.imshow(process_img_obj['lane_img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # load project video\n",
    "# project_video = 'project_video.mp4'\n",
    "# clip1 = VideoFileClip(project_video).subclip(0,5)\n",
    "# white_clip = clip1.fl_image(process_img) #NOTE: this function expects color images!!\n",
    "\n",
    "my_video_processor_object = MyVideoProcessor()\n",
    "output = 'project_video_output_v2_1.mp4'\n",
    "clip = VideoFileClip(\"project_video.mp4\")\n",
    "\n",
    "white_clip = clip.fl_image(my_video_processor_object.pipeline_function)\n",
    "\n",
    "%time white_clip.write_videofile(output, audio=False)\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
